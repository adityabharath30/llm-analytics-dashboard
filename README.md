# ğŸ§  LLM Analytics Dashboard

A lightweight observability tool for LLM-based applications.  
It captures and visualizes prompt logs, model responses, token usage, latency, and cost â€” all in a clean Streamlit dashboard.

---

## ğŸ” Why This Exists

Most LLM apps today lack visibility into what's really happening with prompts, models, and API usage.  
This project helps developers:
- Track and debug prompts
- Monitor model cost and performance
- Compare prompt versions
- Prepare for production scaling

---

## ğŸš€ Features

- ğŸ“ Log prompts, responses, latency, token usage, and cost
- ğŸ§ª Mock mode for development (no API key required)
- ğŸ“Š Streamlit dashboard with live charts and filters
- ğŸ’¾ Supports SQLite (local dev) and PostgreSQL (production)
- ğŸ” Uses `.env` for secure API key and DB config

---

## ğŸ“¦ Tech Stack

- **Python**
- **OpenAI API (optional)**
- **SQLAlchemy**
- **Streamlit**
- **SQLite / PostgreSQL**
- **dotenv**

---

## âš™ï¸ Setup Instructions

### 1. Clone the repo

```bash
git clone https://github.com/YOUR_USERNAME/llm-analytics-dashboard.git
cd llm-analytics-dashboard
